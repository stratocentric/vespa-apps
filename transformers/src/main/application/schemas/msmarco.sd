# Copyright Verizon Media. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root.

schema msmarco {
    document msmarco {

        field id type string {
            indexing: summary | attribute
        }

        field title type string {
            indexing: index | summary
            index: enable-bm25
        }

        field url type string {
            indexing: index | summary
        }

        field body type string {
            indexing: index | summary
            index: enable-bm25
        }

        field tokens type tensor<float>(d0[128]) {
            indexing: attribute
        }

    }

    fieldset default {
        fields: title, body
    }

    onnx-model rank_model {
        file: files/ranking_model.onnx
        input input_ids: input_ids
        input attention_mask: attention_mask
        input token_type_ids: token_type_ids
    }

    rank-profile transformer {

        constants {
            TOKEN_NONE: 0
            TOKEN_CLS: 101
            TOKEN_SEP: 102
        }

        # Find length of input - with the assumption that the
        # input sequence is padded with zeroes.
        function input_length() {
            expression: sum(map(query(input), f(a)(a > 0)))
        }

        # Likewise, find length of the document
        function document_length() {
            expression: sum(map(attribute(tokens), f(a)(a > 0)))
        }

        # Create input sequence: CLS + query + SEP + document + SEP + 0's
        function input_ids() {
            expression {
                tensor<float>(d0[1],d1[128])(
                    if (d1 == 0,
                        TOKEN_CLS,  # 101
                    if (d1 < input_length + 1,
                        query(input){d0:(d1-1)},
                    if (d1 == input_length + 1,
                        TOKEN_SEP,  # 102
                    if (document_length + input_length > 126,
                        if (d1 < 127,
                            attribute(tokens){d0:(d1-input_length-2)},
                            TOKEN_SEP  # 102
                        ),
                        if (d1 < document_length + input_length + 2,
                            attribute(tokens){d0:(d1-input_length-2)},
                            if (d1 == document_length + input_length + 2,
                                TOKEN_SEP,  # 102
                                TOKEN_NONE  # 0
                            )
                        )
                )))))
            }
        }

        # The token type input has 0's for query and 1's for document
        function token_type_ids() {
            expression: tensor<float>(d0[1],d1[128])(if(d1 < input_length + 2, 0, 1))
        }

        # The attention mask has 1's for every token that is set
        function attention_mask() {
            expression: map(input_ids, f(a)(a > 0))
        }

        # Use BM25 as a first phase
        first-phase {
            expression: bm25(title) + bm25(body)
        }

        # The output of this model is a tensor of size ["batch", 2]
        # Use the probability of the positive sequence classification class as rank score
        second-phase {
            rerank-count: 10
            expression: onnx(rank_model){d0:0,d1:1}
        }

    }

}
